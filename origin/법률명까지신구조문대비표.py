import pdfplumber
import pandas as pd
import os
import re
from collections import defaultdict, Counter

def normalize_text(text):
    return (
        text.replace("ã†", "Â·")
            .replace(" ", "")
            .replace("\n", "")
    )

def is_meaningless_dash_row(left, right):
    return all(re.fullmatch(r'[-â€â€‘â€’â€“â€”âˆ’\s]*', side or '') for side in [left, right])

def clean_page_numbers(text):
    if not isinstance(text, str):
        return text
    return re.sub(r'-\s*\d+\s*-?', '', text).strip()

def extract_law_name(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        first_page = pdf.pages[0]
        text = first_page.extract_text()
        if not text:
            return "-"
        lines = text.split('\n')
        for line in lines:
            if any(keyword in line for keyword in ["ë²•ë¥ ", "ê°œì •", "ì‹œí–‰ë ¹", "ì‹œí–‰ê·œì¹™"]):
                return line.strip()
    return "-"

def extract_table_style(pdf_path, start_keyword="ì‹ ã†êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ", line_tol=2):
    result_rows = []
    capturing = False

    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            if not capturing and normalize_text(start_keyword) in normalize_text(text):
                capturing = True

            if capturing:
                words = page.extract_words()
                if not words:
                    continue

                line_map = defaultdict(lambda: {'left': '', 'right': ''})
                midpoint = page.width / 2

                for word in words:
                    top_key = round(word['top'] / line_tol) * line_tol
                    if word['x0'] < midpoint:
                        line_map[top_key]['left'] += ' ' + word['text']
                    else:
                        line_map[top_key]['right'] += ' ' + word['text']

                for top in sorted(line_map.keys()):
                    left = clean_page_numbers(line_map[top]['left'].strip())
                    right = clean_page_numbers(line_map[top]['right'].strip())
                    if not is_meaningless_dash_row(left, right):
                        result_rows.append([left, right])

    return result_rows

def extract_text_by_clause_blocks(pdf_path, start_keyword="ì‹ ã†êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ", max_follow_pages=3):
    capturing = False
    data_pairs = []
    current_left, current_right = [], []
    side = "left"
    follow_page_count = 0

    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if not text:
                continue
            lines = text.split('\n')
            for line in lines:
                line_clean = line.strip()
                if not capturing:
                    if normalize_text(start_keyword) in normalize_text(line):
                        capturing = True
                    continue
                if not line_clean:
                    continue

                if re.match(r"^ì œ?\d+ì¡°", line_clean) or re.match(r"^[\u2460-\u2473\d]+", line_clean) or line_clean.startswith("í˜„í–‰"):
                    if current_left or current_right:
                        l = clean_page_numbers(" ".join(current_left).strip())
                        r = clean_page_numbers(" ".join(current_right).strip())
                        if not is_meaningless_dash_row(l, r):
                            data_pairs.append([l, r])
                        current_left, current_right = [], []
                    side = "left"
                    current_left.append(line_clean)
                elif "ê°œì •ì•ˆ" in line_clean or "í˜„í–‰ê³¼ ê°™ìŒ" in line_clean or "----------------" in line_clean:
                    side = "right"
                else:
                    if side == "left":
                        current_left.append(line_clean)
                    else:
                        current_right.append(line_clean)

            if capturing:
                follow_page_count += 1
                if follow_page_count >= max_follow_pages:
                    break

        if current_left or current_right:
            l = clean_page_numbers(" ".join(current_left).strip())
            r = clean_page_numbers(" ".join(current_right).strip())
            if not is_meaningless_dash_row(l, r):
                data_pairs.append([l, r])

    return data_pairs

def save_final(output_path, data_rows, law_name, method_name=None, add_header=False):
    if not data_rows:
        return False

    # ì¤‘ë³µëœ "í˜„í–‰" + "ê°œì •ì•ˆ" row ì œê±° ë¡œì§
    cleaned_rows = []
    seen = set()
    for row in data_rows:
        if isinstance(row, list) and len(row) >= 2:
            key = (row[0], row[1])
            if key not in seen:
                cleaned_rows.append(row)
                seen.add(key)
        elif isinstance(row, str):
            cleaned_rows.append([row.strip(), ""])

    # ì²« í–‰ì—ë§Œ ë²•ë ¹ëª… í¬í•¨, ì¤‘ë³µ ë°©ì§€
    final_rows = [["ì‹ ã†êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ", law_name]]
    for row in cleaned_rows:
        # "ì‹ ã†êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ" í–‰ ì œê±° (2ë²ˆì§¸ ì´ìƒ ë“±ì¥ ì‹œ)
        if normalize_text(row[0]) == normalize_text("ì‹ ã†êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ"):
            continue
        final_rows.append([row[0].strip(), row[1].strip()])

    df_main = pd.DataFrame(final_rows)
    with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
        df_main.to_excel(writer, index=False, header=False, sheet_name="ì‹ êµ¬ëŒ€ë¹„í‘œ")
        if method_name:
            pd.DataFrame([["ì¶”ì¶œ ë°©ì‹", method_name]]).to_excel(
                writer, index=False, header=False, sheet_name="ì •ë³´"
            )
    return True


results = []

def extract_law_table_auto(pdf_path, output_path):
    base = os.path.basename(pdf_path)
    law_name = extract_law_name(pdf_path)

    rows = extract_table_style(pdf_path)
    if rows and len(rows) > 2:
        print(f"âœ… [í‘œ ê¸°ë°˜] ì¶”ì¶œ ì„±ê³µ: {base}")
        if save_final(output_path, rows, law_name):
            results.append((base, "í‘œ ê¸°ë°˜", law_name))
            return
    rows = extract_text_by_clause_blocks(pdf_path)
    if rows and len(rows) > 2:
        print(f"âœ… [ì¡°ë¬¸ë¸”ë¡ fallback] ì¶”ì¶œ ì„±ê³µ: {base}")
        if save_final(output_path, rows, law_name, method_name="ì¡°ë¬¸ë¸”ë¡ fallback", add_header=True):
            results.append((base, "ì¡°ë¬¸ë¸”ë¡ fallback", law_name))
            return
    print(f"âŒ ìµœì¢… ì¶”ì¶œ ì‹¤íŒ¨: {base}")
    results.append((base, "ì‹¤íŒ¨", law_name))

def process_folder(input_folder, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    for filename in os.listdir(input_folder):
        if filename.lower().endswith(".pdf"):
            pdf_path = os.path.join(input_folder, filename)
            name_only = os.path.splitext(filename)[0]
            output_path = os.path.join(output_folder, f"{name_only}_ì‹ êµ¬ëŒ€ë¹„í‘œ.xlsx")
            extract_law_table_auto(pdf_path, output_path)
    summary = Counter(method for _, method, _ in results)
    print("\nğŸ“Š ì²˜ë¦¬ í†µê³„ ìš”ì•½")
    for method in ["í‘œ ê¸°ë°˜", "ì¡°ë¬¸ë¸”ë¡ fallback", "ì‹¤íŒ¨"]:
        print(f"{method:>15}: {summary.get(method, 0)}ê±´")
    failed = [name for name, method, _ in results if method == "ì‹¤íŒ¨"]
    if failed:
        print("\nâ— ì‹¤íŒ¨í•œ íŒŒì¼ ëª©ë¡:")
        for name in failed:
            print(f"- {name}")

if __name__ == "__main__":
    input_folder = r"D:\\1.ì”¨ì§€ì¸ì‚¬ì´ë“œ\\1. ì œì•ˆ ì—…ë¬´\\15. IBK í¼ìŠ¤íŠ¸ë©\\pdftable"
    output_folder = r"D:\\1.ì”¨ì§€ì¸ì‚¬ì´ë“œ\\1. ì œì•ˆ ì—…ë¬´\\15. IBK í¼ìŠ¤íŠ¸ë©\\pdftable"
    process_folder(input_folder, output_folder)
