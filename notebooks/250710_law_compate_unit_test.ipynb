{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d407a4",
   "metadata": {},
   "source": [
    "ğŸ” Step 1: ë ˆì´ì•„ì›ƒ ìë™ íƒì§€ ë¹„êµ ì „ëµ\n",
    "| í•­ëª©    | ê¸°ì¡´ ë°©ì‹ (`pdfplumber`)      | ì œì•ˆ ë°©ì‹ (`layout-parser + PyMuPDF`) |\n",
    "| ----- | ------------------------- | --------------------------------- |\n",
    "| ì¶”ì¶œ ê¸°ì¤€ | `extract_words()`ë¡œ ì¢Œìš° ë‚˜ëˆ„ê¸° | í…ìŠ¤íŠ¸ ë°•ìŠ¤(layout element)ë¡œ ì¢Œìš° ìë™ ë¶„ë¦¬  |\n",
    "| ê¸°ì¤€ì    | `x0 < midpoint` ì§ì ‘ ê³„ì‚°     | ìë™ ë°•ìŠ¤ ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§               |\n",
    "| í•œê³„    | ê¸€ì ë°€ë„/ì¤„ë°”ê¿ˆì— ë”°ë¼ ë¼ì¸ ê¹¨ì§       | ë ˆì´ì•„ì›ƒ ì•Œê³ ë¦¬ì¦˜ì´ ëœ ê¹¨ì§                   |\n",
    "| ì¥ì     | êµ¬ì¡°ê°€ ë‹¨ìˆœ, ë¹ ë¦„                | ìœ„ì¹˜ ì •ë°€ë„ ìš°ìˆ˜, ë‹¤ì–‘í•œ í¬ë§· ëŒ€ì‘              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521b55a",
   "metadata": {},
   "source": [
    "âœ… í…ŒìŠ¤íŠ¸ í•­ëª© ì •ì˜\n",
    "| í•­ëª©      | ëª©í‘œ              | ë°©ì‹                                 |\n",
    "| ------- | --------------- | ---------------------------------- |\n",
    "| **1ë‹¨ê³„** | ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ í˜ì´ì§€ ê°ì§€  | `normalize_text()`ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜         |\n",
    "| **2ë‹¨ê³„** | ì¢Œìš° í…ìŠ¤íŠ¸ ë¸”ë¡ ë¶„ë¦¬    | `pdfplumber` vs `layout-parser` ë¹„êµ |\n",
    "| **3ë‹¨ê³„** | ì¡°ë¬¸ ê°ì§€ (ì œxì¡°)     | ì •ê·œí‘œí˜„ì‹ ìœ ì—°í™” í›„ ì ìš©                     |\n",
    "| **4ë‹¨ê³„** | ë‹¨ì¼ PDF ì²˜ë¦¬ ê²°ê³¼ ë¹„êµ | ì¶”ì¶œëœ row ìˆ˜, í¬ë§· ë¹„êµ                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4545f2a",
   "metadata": {},
   "source": [
    "ğŸ§ª ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì „ëµ\n",
    "### ğŸ“„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê³„íš (Notionìš© Mermaid ì˜ˆì‹œ)\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[PDF íŒŒì¼ 1ê°œ ì„ íƒ] --> B1[pdfplumber ë°©ì‹ ì¶”ì¶œ]\n",
    "    A --> B2[layout-parser ë°©ì‹ ì¶”ì¶œ]\n",
    "    B1 --> C1[ì¡°ë¬¸ ìˆ˜ ì¹´ìš´íŠ¸]\n",
    "    B2 --> C2[ì¡°ë¬¸ ìˆ˜ ì¹´ìš´íŠ¸]\n",
    "    C1 --> D[ê²°ê³¼ ë¹„êµ]\n",
    "    C2 --> D\n",
    "    D --> E{ì–´ëŠ ìª½ì´ ì•ˆì •ì ?}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98362c15",
   "metadata": {},
   "source": [
    "## âœ… Step 1: ì‹ êµ¬ ëŒ€ë¹„í‘œ í˜ì´ì§€ ìë™ íƒì§€ + ì¢Œìš° ë¶„ë¦¬ (2ë°©ì‹) ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì½”ë“œ   \n",
    "ğŸ¯ ëª©í‘œ\n",
    " - PDFì—ì„œ \"ì‹ Â·êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ\" í˜ì´ì§€ ê°ì§€\n",
    "\n",
    " - ê°ì§€ëœ í˜ì´ì§€ì—ì„œ ì¢Œì¸¡(í˜„í–‰), ìš°ì¸¡(ê°œì •ì•ˆ) í…ìŠ¤íŠ¸ë¥¼ ê°ê° ì¶”ì¶œ\n",
    "\n",
    " - ë°©ì‹ 1: pdfplumber\n",
    "\n",
    " - ë°©ì‹ 2: layoutparser + PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bdc288",
   "metadata": {},
   "source": [
    "### âœ… ë°©ì‹ 1: pdfplumber ê¸°ë°˜ ì¢Œìš° ë¸”ë¡ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a097922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_with_pdfplumber(file_path, start_keyword=\"ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ\", line_tol=2):\n",
    "    result_rows = []\n",
    "    capturing = False\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text() or \"\"\n",
    "            if not capturing and start_keyword in text:\n",
    "                capturing = True\n",
    "\n",
    "            if capturing:\n",
    "                words = page.extract_words()\n",
    "                if not words:\n",
    "                    continue\n",
    "                midpoint = page.width / 2\n",
    "                line_map = defaultdict(lambda: {\"left\": \"\", \"right\": \"\"})\n",
    "\n",
    "                for word in words:\n",
    "                    top_key = round(word['top'] / line_tol) * line_tol\n",
    "                    if word['x0'] < midpoint:\n",
    "                        line_map[top_key][\"left\"] += \" \" + word['text']\n",
    "                    else:\n",
    "                        line_map[top_key][\"right\"] += \" \" + word['text']\n",
    "\n",
    "                for top in sorted(line_map.keys()):\n",
    "                    l = line_map[top]['left'].strip()\n",
    "                    r = line_map[top]['right'].strip()\n",
    "                    if l or r:\n",
    "                        result_rows.append([l, r])\n",
    "    return result_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805bbfc1",
   "metadata": {},
   "source": [
    "### âœ… ë°©ì‹ 2: layoutparser + PyMuPDF ê¸°ë°˜ í…ìŠ¤íŠ¸ ë°•ìŠ¤ ì¢Œìš° ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d04fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_with_layoutparser(file_path, start_keyword=\"ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ\", line_tol=15):\n",
    "    result_rows = []\n",
    "    model = lp.Detectron2LayoutModel(\n",
    "        config_path='lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
    "        label_map={0: \"Text\"},\n",
    "        extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8]\n",
    "    )\n",
    "\n",
    "    doc = fitz.open(file_path)\n",
    "    for page_num, page in enumerate(doc):\n",
    "        text = page.get_text()\n",
    "        if start_keyword not in text:\n",
    "            continue\n",
    "\n",
    "        pix = page.get_pixmap(dpi=200)\n",
    "        image = lp.io.load_image(pix.samples, pix.width, pix.height)\n",
    "        layout = model.detect(image)\n",
    "\n",
    "        left_text, right_text = \"\", \"\"\n",
    "        midpoint = image.shape[1] / 2\n",
    "\n",
    "        for block in layout:\n",
    "            if block.type != \"Text\":\n",
    "                continue\n",
    "            block_text = block.text.strip()\n",
    "            if block_text:\n",
    "                if block.block.x_1 < midpoint:\n",
    "                    left_text += block_text + \"\\n\"\n",
    "                else:\n",
    "                    right_text += block_text + \"\\n\"\n",
    "\n",
    "        result_rows.append([left_text.strip(), right_text.strip()])\n",
    "        break  # ì²« ë°œê²¬ í˜ì´ì§€ë§Œ ì¶”ì¶œ\n",
    "    return result_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1b4c5",
   "metadata": {},
   "source": [
    "### âœ… ì „ì²´ ìˆœíšŒ í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "\n",
    "```\n",
    "pip install layoutparser[layoutmodels] pdfplumber pymupdf opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c0c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2205429_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2205429_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2207157_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2207157_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2208369_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2208369_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2208659_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2208659_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2208853_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2208853_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210255_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210255_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210437_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210437_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210469_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210469_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210471_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210471_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210483_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210483_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210491_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210491_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210496_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210496_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210568_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210568_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210578_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210578_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210585_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210585_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\2210588_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\2210588_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\file.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\file.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n",
      "\n",
      "ğŸ“„ íŒŒì¼: ..\\data\\no_upload\\fileì‚­ì œìˆëŠ”ê²ƒ.pdf\n",
      "âŒ PDFPlumber ì‹¤íŒ¨: [Errno 2] No such file or directory: '..\\\\data\\\\no_upload\\\\..\\\\data\\\\no_upload\\\\fileì‚­ì œìˆëŠ”ê²ƒ.pdf'\n",
      "âŒ LayoutParser ì‹¤íŒ¨: module layoutparser has no attribute Detectron2LayoutModel\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ ì„¤ì •\n",
    "pdf_dir = Path(\"../data/no_upload\")  # PDFê°€ ìˆëŠ” í´ë”\n",
    "pdf_files = pdf_dir.glob(\"*.pdf\")\n",
    "\n",
    "# âœ… ìˆœíšŒ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def run_test_on_all_pdfs():\n",
    "    for file_name in pdf_files:\n",
    "        path = str(pdf_dir / file_name)\n",
    "        print(f\"\\nğŸ“„ íŒŒì¼: {file_name}\")\n",
    "\n",
    "        try:\n",
    "            plumber_result = extract_with_pdfplumber(path)\n",
    "            print(f\"âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: {len(plumber_result)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PDFPlumber ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "        try:\n",
    "            layout_result = extract_with_layoutparser(path)\n",
    "            print(f\"âœ… LayoutParser ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: {len(layout_result)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LayoutParser ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ğŸ” í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "run_test_on_all_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5f04ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sokch\\.conda\\envs\\ibk\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ LayoutParser ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: \n",
      "Detectron2LayoutModel requires the detectron2 library but it was not found in your environment. Checkout the instructions on the\n",
      "installation page: https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md and follow the ones\n",
      "that match your environment. Typically the following would work for MacOS or Linux CPU machines:\n",
      "    pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2' \n",
      "\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2205429_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2207157_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2208369_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2208659_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2208853_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210255_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210437_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210469_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210471_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210483_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210491_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210496_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210568_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210578_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210585_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: 2210588_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: file.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n",
      "\n",
      "ğŸ“„ íŒŒì¼: fileì‚­ì œìˆëŠ”ê²ƒ.pdf\n",
      "âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: 0\n",
      "âŒ LayoutParser ì‹¤íŒ¨: layout_model ë¯¸ë¡œë”©\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# âœ… layoutparserìš© ëª¨ë¸ ë¡œë”© (í•œ ë²ˆë§Œ)\n",
    "try:\n",
    "    from layoutparser.models import Detectron2LayoutModel\n",
    "    layout_model = Detectron2LayoutModel(\n",
    "        config_path='lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
    "        label_map={0: \"Text\"},\n",
    "        extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8]\n",
    "    )\n",
    "except Exception as e:\n",
    "    layout_model = None\n",
    "    print(f\"âŒ LayoutParser ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ ì„¤ì •\n",
    "pdf_dir = Path(\"../data/no_upload\")\n",
    "pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "\n",
    "# âœ… ìˆœíšŒ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def run_test_on_all_pdfs():\n",
    "    for file_path in pdf_files:\n",
    "        print(f\"\\nğŸ“„ íŒŒì¼: {file_path.name}\")\n",
    "\n",
    "        try:\n",
    "            plumber_result = extract_with_pdfplumber(str(file_path))\n",
    "            print(f\"âœ… PDFPlumber ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: {len(plumber_result)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PDFPlumber ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "        try:\n",
    "            if layout_model is None:\n",
    "                raise RuntimeError(\"layout_model ë¯¸ë¡œë”©\")\n",
    "            layout_result = extract_with_layoutparser(str(file_path), layout_model)\n",
    "            print(f\"âœ… LayoutParser ì¶”ì¶œ ì„±ê³µ - í–‰ ìˆ˜: {len(layout_result)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LayoutParser ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ğŸ” í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "run_test_on_all_pdfs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7c8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pdfplumber\n",
    "\n",
    "def extract_with_pdfplumber(path, line_tol=1):\n",
    "    result_rows = []\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            words = page.extract_words()\n",
    "            if not words:\n",
    "                continue\n",
    "\n",
    "            midpoint = page.width / 2\n",
    "            line_map = defaultdict(lambda: {'left': '', 'right': ''})\n",
    "\n",
    "            for word in words:\n",
    "                top_key = round(word['top'] / line_tol) * line_tol\n",
    "                if word['x0'] < midpoint:\n",
    "                    line_map[top_key]['left'] += ' ' + word['text']\n",
    "                else:\n",
    "                    line_map[top_key]['right'] += ' ' + word['text']\n",
    "\n",
    "            for top in sorted(line_map.keys()):\n",
    "                l = line_map[top]['left'].strip()\n",
    "                r = line_map[top]['right'].strip()\n",
    "\n",
    "                # âœ… í•„í„° ì¡°ê±´ ì„ì‹œ ì œê±°\n",
    "                # if not is_meaningless_dash_row(l, r): â† ì œê±°\n",
    "                result_rows.append([l, r])\n",
    "    return result_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39242697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ê³µíœ´ì¼ì— ê´€í•œ ë²•ë¥ ', 'ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ'],\n",
       " ['(ê¹€ì¬ì„­ì˜ì›', 'ëŒ€í‘œë°œì˜)'],\n",
       " ['ë°œì˜ì—°ì›”ì¼', ': 2025. 5. 12.'],\n",
       " ['ì˜ ì•ˆ', ''],\n",
       " ['10471', ''],\n",
       " ['ë²ˆ í˜¸', ''],\n",
       " ['', 'ê¹€ì¬ì„­ã†ë°±ì¢…í—Œã†ì—„íƒœì˜'],\n",
       " ['ë°œ', 'ì˜ ì :'],\n",
       " ['', 'ì„œì²œí˜¸ã†ìœ¤í•œí™ã†ê¶Œì˜ì§„'],\n",
       " ['', 'ê°•ìŠ¹ê·œã†ìµœìˆ˜ì§„ã†ì‹ ì„±ë²”'],\n",
       " ['', 'ë°•ë•í  ì˜ì›(10ì¸)'],\n",
       " ['ì œì•ˆì´ìœ  ë° ì£¼ìš”ë‚´ìš©', ''],\n",
       " ['ì €ì¶œì‚°ã†ê³ ë ¹ì‚¬íšŒ', ''],\n",
       " ['ã€Œì œ4ì°¨ ê¸°ë³¸ê³„íšã€ì€', 'ì €ì¶œì‚°ì˜ ì›ì¸ê³¼ ê´€ë ¨í•˜ì—¬'],\n",
       " ['ì¼ê°€ì • ì–‘ë¦½ì„ ì €í•´í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ', 'ì¥ì‹œê°„ ê·¼ë¡œì™€ ê³¼ì†Œí•œ íœ´ê°€ì¼ìˆ˜ë¥¼'],\n",
       " ['ì ì‹œí•˜ê³  ìˆìœ¼ë‚˜ ìœ ê¸‰ ê³µíœ´ì¼ ë„ì…ì—', 'ëŒ€í•˜ì—¬ëŠ” ê´€ë ¨ ë…¼ì˜ê°€ ì—†ìŒ.'],\n",
       " ['5ì›” ë‘ ë²ˆì§¸ ê¸ˆìš”ì¼ì„ ê°€ì¡±ë¬¸í™”ì˜', 'ë‚ ë¡œ ì§€ì •í•˜ì—¬ ê°€ì¡±ì¹œí™”ì  íœ´ì¼'],\n",
       " ['ì œë„ë¥¼ ë§ˆë ¨í•¨ìœ¼ë¡œì¨ ì¼ê°€ì • ì–‘ë¦½ì„', 'ìœ„í•œ íœ´ê°€ í•„ìš”ì„±ì— ëŒ€í•œ ì¸ì‹ì„'],\n",
       " ['ì œê³ í•˜ë ¤ëŠ” ê²ƒì„(ì•ˆ ì œ2ì¡°ì œ6í˜¸ ì‹ ì„¤).', ''],\n",
       " ['- 1', '-'],\n",
       " ['ë²•ë¥  ì œ í˜¸', ''],\n",
       " ['ê³µíœ´ì¼ì— ê´€í•œ ë²•ë¥ ', 'ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ'],\n",
       " ['ê³µíœ´ì¼ì— ê´€í•œ ë²•ë¥  ì¼ë¶€ë¥¼ ë‹¤ìŒê³¼', 'ê°™ì´ ê°œì •í•œë‹¤.'],\n",
       " ['ì œ2ì¡°ì œ6í˜¸ë¶€í„° ì œ10í˜¸ê¹Œì§€ë¥¼ ê°ê°', 'ì œ7í˜¸ë¶€í„° ì œ11í˜¸ê¹Œì§€ë¡œ í•˜ê³ , ê°™'],\n",
       " ['ì€ ì¡°ì— ì œ6í˜¸ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì‹ ì„¤í•œë‹¤.', ''],\n",
       " ['6. ê°€ì¡±ë¬¸í™”ì˜ ë‚ (5ì›” ë‘ ë²ˆì§¸ ê¸ˆìš”ì¼)', ''],\n",
       " ['ë¶€', 'ì¹™'],\n",
       " ['ì´ ë²•ì€ ê³µí¬í•œ ë‚ ë¶€í„° ì‹œí–‰í•œë‹¤.', ''],\n",
       " ['- 3', '-'],\n",
       " ['ì‹ ã†êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ', ''],\n",
       " ['í˜„ í–‰', 'ê°œ ì • ì•ˆ'],\n",
       " ['ì œ2ì¡°(ê³µíœ´ì¼) ê³µíœ´ì¼ì€ ë‹¤ìŒ ê°', 'ì œ2ì¡°(ê³µíœ´ì¼) --------------'],\n",
       " ['í˜¸ì™€ ê°™ë‹¤.', '------------.'],\n",
       " ['1. âˆ¼ 5. (ìƒ ëµ)', '1. âˆ¼ 5. (í˜„í–‰ê³¼ ê°™ìŒ)'],\n",
       " ['<ì‹  ì„¤>', '6. ê°€ì¡±ë¬¸í™”ì˜ ë‚ (5ì›” ë‘ ë²ˆì§¸'],\n",
       " ['', 'ê¸ˆìš”ì¼)'],\n",
       " ['6. âˆ¼ 10. (ìƒ ëµ)', '7. âˆ¼ 11. (í˜„í–‰ ì œ6í˜¸ë¶€í„° ì œ1'],\n",
       " ['', '0í˜¸ê¹Œì§€ì™€ ê°™ìŒ)'],\n",
       " ['- 5', '-']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_with_pdfplumber(r\"C:\\Jimin\\cg_DeltaLaw\\data\\no_upload\\2210471_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf99b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_with_pdfplumber_v2(path, line_tol=1):\n",
    "    result_rows = []\n",
    "    capturing = False\n",
    "\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text() or \"\"\n",
    "            if not capturing and ('ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ' in text or 'í˜„ í–‰' in text):\n",
    "                capturing = True\n",
    "\n",
    "            if not capturing:\n",
    "                continue\n",
    "\n",
    "            words = page.extract_words()\n",
    "            if not words:\n",
    "                continue\n",
    "\n",
    "            midpoint = page.width / 2\n",
    "            line_map = defaultdict(lambda: {\"left\": \"\", \"right\": \"\"})\n",
    "\n",
    "            for word in words:\n",
    "                top_key = round(word['top'] / line_tol) * line_tol\n",
    "                if word['x0'] < midpoint:\n",
    "                    line_map[top_key][\"left\"] += \" \" + word['text']\n",
    "                else:\n",
    "                    line_map[top_key][\"right\"] += \" \" + word['text']\n",
    "\n",
    "            for top in sorted(line_map.keys()):\n",
    "                l = line_map[top]['left'].strip()\n",
    "                r = line_map[top]['right'].strip()\n",
    "                result_rows.append([l, r])\n",
    "\n",
    "    # âœ… í›„ì²˜ë¦¬: ì˜¤ë¥¸ìª½ ì¤„ë§Œ ìˆëŠ” ê²½ìš° ì´ì „ í–‰ê³¼ ë³‘í•©\n",
    "    merged_rows = []\n",
    "    for row in result_rows:\n",
    "        if merged_rows and row[0] == \"\" and row[1]:\n",
    "            merged_rows[-1][1] += \" \" + row[1]\n",
    "        else:\n",
    "            merged_rows.append(row)\n",
    "\n",
    "    return merged_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2822e440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ì‹ ã†êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ', ''],\n",
       " ['í˜„ í–‰', 'ê°œ ì • ì•ˆ'],\n",
       " ['ì œ2ì¡°(ê³µíœ´ì¼) ê³µíœ´ì¼ì€ ë‹¤ìŒ ê°', 'ì œ2ì¡°(ê³µíœ´ì¼) --------------'],\n",
       " ['í˜¸ì™€ ê°™ë‹¤.', '------------.'],\n",
       " ['1. âˆ¼ 5. (ìƒ ëµ)', '1. âˆ¼ 5. (í˜„í–‰ê³¼ ê°™ìŒ)'],\n",
       " ['<ì‹  ì„¤>', '6. ê°€ì¡±ë¬¸í™”ì˜ ë‚ (5ì›” ë‘ ë²ˆì§¸ ê¸ˆìš”ì¼)'],\n",
       " ['6. âˆ¼ 10. (ìƒ ëµ)', '7. âˆ¼ 11. (í˜„í–‰ ì œ6í˜¸ë¶€í„° ì œ1 0í˜¸ê¹Œì§€ì™€ ê°™ìŒ)'],\n",
       " ['- 5', '-']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_with_pdfplumber_v2(r\"C:\\Jimin\\cg_DeltaLaw\\data\\no_upload\\2210471_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6620d",
   "metadata": {},
   "source": [
    "flowchart TD\n",
    "    A[PDFPlumberë¡œ ì¤„ ì¶”ì¶œ] --> B[ì¢Œìš° ë³‘í•© ì¤„ ë¦¬ìŠ¤íŠ¸]\n",
    "    B --> C[ì¡°ë¬¸ ì‹œì‘ íŒ¨í„´ìœ¼ë¡œ ë¸”ë¡ ë¶„í• ]\n",
    "    C --> D[ì¢Œìš° ë¸”ë¡ ë¹„êµ â†’ ë³€ê²½ìœ í˜• íŒì •]\n",
    "    D --> E[CSV + Excelë¡œ ì €ì¥]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9518728",
   "metadata": {},
   "source": [
    "### ì „ì²´ íŒŒì¼ ìˆœíšŒ + ì²˜ë¦¬ + ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70622608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2205429_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2207157_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2208369_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2208659_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2208853_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210255_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210437_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210469_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210471_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210483_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210491_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210496_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210568_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210578_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210585_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: 2210588_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: file.pdf\n",
      "ğŸ“„ ì²˜ë¦¬ ì¤‘: fileì‚­ì œìˆëŠ”ê²ƒ.pdf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def split_by_clause(rows):\n",
    "    \"\"\"ì¡°ë¬¸ ì‹œì‘ ê¸°ì¤€ìœ¼ë¡œ ë¸”ë¡ ë‹¨ìœ„ ë¬¶ê¸°\"\"\"\n",
    "    def is_clause_start(text):\n",
    "        return bool(re.match(r\"^ì œ?\\d+ì¡°\", text)) or bool(re.match(r\"^[â‘ -â‘©\\d]+\\.\", text))\n",
    "\n",
    "    left_blocks, right_blocks = [], []\n",
    "    cur_left, cur_right = [], []\n",
    "\n",
    "    for l, r in rows:\n",
    "        if is_clause_start(l):\n",
    "            if cur_left or cur_right:\n",
    "                left_blocks.append(\"\\n\".join(cur_left).strip())\n",
    "                right_blocks.append(\"\\n\".join(cur_right).strip())\n",
    "                cur_left, cur_right = [], []\n",
    "            cur_left.append(l)\n",
    "            cur_right.append(r)\n",
    "        else:\n",
    "            cur_left.append(l)\n",
    "            cur_right.append(r)\n",
    "\n",
    "    if cur_left or cur_right:\n",
    "        left_blocks.append(\"\\n\".join(cur_left).strip())\n",
    "        right_blocks.append(\"\\n\".join(cur_right).strip())\n",
    "\n",
    "    return list(zip(left_blocks, right_blocks))\n",
    "\n",
    "def classify_change_type(left, right):\n",
    "    \"\"\"ë³€ê²½ìœ í˜• íŒì •\"\"\"\n",
    "    if left and not right:\n",
    "        return \"ì‚­ì œ\"\n",
    "    elif right and not left:\n",
    "        return \"ì‹ ì„¤\"\n",
    "    elif left == right:\n",
    "        return \"ë™ì¼\"\n",
    "    else:\n",
    "        import difflib\n",
    "        sim = difflib.SequenceMatcher(None, left, right).ratio()\n",
    "        return \"ë™ì¼\" if sim >= 0.85 else \"ë³€ê²½\"\n",
    "\n",
    "def process_pdf_file(file_path, out_dir):\n",
    "    rows = extract_with_pdfplumber_v2(str(file_path))\n",
    "    clause_pairs = split_by_clause(rows)\n",
    "    data = []\n",
    "\n",
    "    for left, right in clause_pairs:\n",
    "        change_type = classify_change_type(left, right)\n",
    "        data.append({\n",
    "            \"í˜„í–‰\": left,\n",
    "            \"ê°œì •ì•ˆ\": right,\n",
    "            \"ë³€ê²½ìœ í˜•\": change_type\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    law_name = file_path.stem\n",
    "    df.to_csv(out_dir / f\"{law_name}_ì¡°ë¬¸ë¹„êµê²°ê³¼.csv\", index=False)\n",
    "    df.to_excel(out_dir / f\"{law_name}_ì¡°ë¬¸ë¹„êµê²°ê³¼.xlsx\", index=False)\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ ì„¤ì •\n",
    "import re\n",
    "pdf_dir = Path(\"../data/no_upload\")\n",
    "out_dir = Path(\"../data/processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "\n",
    "# âœ… ì „ì²´ ìˆœíšŒ ì‹¤í–‰\n",
    "for file_path in pdf_files:\n",
    "    print(f\"ğŸ“„ ì²˜ë¦¬ ì¤‘: {file_path.name}\")\n",
    "    process_pdf_file(file_path, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2582ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PDF ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:05<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_by_clause(rows):\n",
    "    def is_clause_start(text):\n",
    "        return bool(re.match(r\"^ì œ?\\d+ì¡°\", text)) or bool(re.match(r\"^[â‘ -â‘©\\d]+\\.\", text))\n",
    "\n",
    "    left_blocks, right_blocks = [], []\n",
    "    cur_left, cur_right = [], []\n",
    "\n",
    "    for l, r in rows:\n",
    "        if is_clause_start(l):\n",
    "            if cur_left or cur_right:\n",
    "                left_blocks.append(\"\\n\".join(cur_left).strip())\n",
    "                right_blocks.append(\"\\n\".join(cur_right).strip())\n",
    "                cur_left, cur_right = [], []\n",
    "            cur_left.append(l)\n",
    "            cur_right.append(r)\n",
    "        else:\n",
    "            cur_left.append(l)\n",
    "            cur_right.append(r)\n",
    "\n",
    "    if cur_left or cur_right:\n",
    "        left_blocks.append(\"\\n\".join(cur_left).strip())\n",
    "        right_blocks.append(\"\\n\".join(cur_right).strip())\n",
    "\n",
    "    return list(zip(left_blocks, right_blocks))\n",
    "\n",
    "def classify_change_type(left, right):\n",
    "    if left and not right:\n",
    "        return \"ì‚­ì œ\"\n",
    "    elif right and not left:\n",
    "        return \"ì‹ ì„¤\"\n",
    "    elif left == right:\n",
    "        return \"ë™ì¼\"\n",
    "    else:\n",
    "        import difflib\n",
    "        sim = difflib.SequenceMatcher(None, left, right).ratio()\n",
    "        return \"ë™ì¼\" if sim >= 0.85 else \"ë³€ê²½\"\n",
    "\n",
    "def process_pdf_and_append(file_path):\n",
    "    rows = extract_with_pdfplumber_v2(str(file_path))\n",
    "    clause_pairs = split_by_clause(rows)\n",
    "    records = []\n",
    "\n",
    "    for left, right in clause_pairs:\n",
    "        change_type = classify_change_type(left, right)\n",
    "        records.append({\n",
    "            \"íŒŒì¼ëª…\": file_path.name,\n",
    "            \"í˜„í–‰\": left,\n",
    "            \"ê°œì •ì•ˆ\": right,\n",
    "            \"ë³€ê²½ìœ í˜•\": change_type\n",
    "        })\n",
    "\n",
    "    return records\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ\n",
    "pdf_dir = Path(\"../data/no_upload\")\n",
    "out_dir = Path(\"../data/processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "\n",
    "# âœ… ì „ì²´ ìˆœíšŒ í›„ í†µí•© ì €ì¥\n",
    "all_records = []\n",
    "for file_path in tqdm(pdf_files, desc=\"PDF ì²˜ë¦¬ ì¤‘\"):\n",
    "    all_records.extend(process_pdf_and_append(file_path))\n",
    "\n",
    "df_all = pd.DataFrame(all_records)\n",
    "df_all.to_csv(out_dir / \"unit_test_ì¡°ë¬¸_ì „ì²´ë¹„êµê²°ê³¼.csv\", index=False)\n",
    "df_all.to_excel(out_dir / \"unit_test_ì¡°ë¬¸_ì „ì²´ë¹„êµê²°ê³¼.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6defc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
