{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "490c2876",
   "metadata": {},
   "source": [
    "âœ… v3 ì½”ë“œ ë°˜ì˜ ì™„ë£Œ.  \n",
    "ë‹¤ìŒ í•­ëª©ì´ í¬í•¨ë¨:\n",
    "\n",
    "- ë²•ë ¹ëª…, ê°œì •ìœ í˜•, ì˜ì•ˆë²ˆí˜¸, ë°œì˜ì¼ â†’ extract_meta()ë¡œ í•œ ë²ˆì— ì¶”ì¶œ\n",
    "\n",
    "- ì „ë¶€ê°œì • ì˜ˆì™¸ì²˜ë¦¬ í¬í•¨\n",
    "\n",
    "- ì‹ êµ¬ì¡°ë¬¸ ë¹„êµ ê²°ê³¼ëŠ” CSVì— ì €ì¥ë˜ì§€ë§Œ, ë©”íƒ€ë°ì´í„°ëŠ” ë”°ë¡œ dict í˜•íƒœë¡œ ë°˜í™˜\n",
    "\n",
    "- í•¨ìˆ˜ process_single_pdf()ê°€ ì „ì²´ íë¦„ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0305c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "import csv\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        text = \"\\n\".join(\n",
    "            page.extract_text() for page in pdf.pages if page.extract_text()\n",
    "        )\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_meta(text):\n",
    "    meta = {}\n",
    "    law_match = re.search(r\"([\\w\\dê°€-í£]+ë²•)\\s*(ì¼ë¶€|ì „ë¶€)?ê°œì •ë²•ë¥ ì•ˆ\", text)\n",
    "    if law_match:\n",
    "        meta[\"ë²•ë ¹ëª…\"] = law_match.group(1)\n",
    "        meta[\"ê°œì •ìœ í˜•\"] = law_match.group(2)\n",
    "    bill_match = re.search(r\"ì˜ì•ˆ[\\s:ï¼š]*ë²ˆí˜¸[\\s:ï¼š]*(ì œ?\\d+í˜¸)\", text)\n",
    "    if bill_match:\n",
    "        meta[\"ì˜ì•ˆë²ˆí˜¸\"] = bill_match.group(1)\n",
    "    date_match = re.search(r\"ë°œì˜[\\s:ï¼š]*ì—°ì›”ì¼[\\s:ï¼š]*([\\d\\.\\-]+)\", text)\n",
    "    if date_match:\n",
    "        meta[\"ë°œì˜ì—°ì›”ì¼\"] = date_match.group(1)\n",
    "    return meta\n",
    "\n",
    "\n",
    "def extract_table_section(text):\n",
    "    lines = text.splitlines()\n",
    "    start_idx = next((i for i, line in enumerate(lines) if \"ì‹ \" in line and \"êµ¬\" in line), 0)\n",
    "    return \"\\n\".join(lines[start_idx:])\n",
    "\n",
    "\n",
    "def split_left_right(text):\n",
    "    lines = text.splitlines()\n",
    "    left_lines, right_lines = [], []\n",
    "    midpoint = max(len(line) for line in lines) // 2\n",
    "    for line in lines:\n",
    "        left = line[:midpoint].strip()\n",
    "        right = line[midpoint:].strip()\n",
    "        left_lines.append(left)\n",
    "        right_lines.append(right)\n",
    "    return \"\\n\".join(left_lines), \"\\n\".join(right_lines)\n",
    "\n",
    "\n",
    "def split_by_clause(text):\n",
    "    pattern = r\"(ì œ\\d+ì¡°(?:\\s*ì œ\\d+í•­)?(?:\\s*ì œ\\d+í˜¸)?(?:\\s*ì œ\\d+ëª©)?)\"\n",
    "    parts = re.split(pattern, text)\n",
    "    clauses = []\n",
    "    for i in range(1, len(parts), 2):\n",
    "        law_id = parts[i].strip()\n",
    "        law_body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "        clauses.append((law_id, law_body))\n",
    "    return clauses\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    remove_keywords = [\"í˜„í–‰ê³¼ ê°™ìŒ\", \"------\", \"ìƒëµ\"]\n",
    "    lines = text.splitlines()\n",
    "    lines = [line.strip() for line in lines if line.strip() and not any(k in line for k in remove_keywords)]\n",
    "    return \" \".join(lines)\n",
    "\n",
    "\n",
    "def compare_clauses_v2(old_clauses, new_clauses, similarity_threshold=0.85):\n",
    "    results = []\n",
    "    old_dict = {cid: clean_text(text) for cid, text in old_clauses}\n",
    "    new_ids = set(cid for cid, _ in new_clauses)\n",
    "\n",
    "    for cid, new_text_raw in new_clauses:\n",
    "        new_text = clean_text(new_text_raw)\n",
    "        old_text = old_dict.get(cid)\n",
    "        if old_text:\n",
    "            sim = SequenceMatcher(None, old_text, new_text).ratio()\n",
    "            if sim < similarity_threshold:\n",
    "                results.append((cid, old_text, new_text, \"ìˆ˜ì •\"))\n",
    "        else:\n",
    "            results.append((cid, \"\", new_text, \"ì‹ ì„¤\"))\n",
    "\n",
    "    for cid, old_text_raw in old_clauses:\n",
    "        if cid not in new_ids:\n",
    "            old_text = clean_text(old_text_raw)\n",
    "            results.append((cid, old_text, \"\", \"ì‚­ì œ\"))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_to_csv(data, path):\n",
    "    with open(path, mode=\"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"ì¡°ë¬¸ ID\", \"êµ¬ì¡°ë¬¸\", \"ì‹ ì¡°ë¬¸\", \"ë³€ê²½ìœ í˜•\"])\n",
    "        for row in data:\n",
    "            writer.writerow(list(row))\n",
    "\n",
    "\n",
    "def process_single_pdf(pdf_path, output_csv):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    meta = extract_meta(text)\n",
    "    if meta.get(\"ê°œì •ìœ í˜•\") == \"ì „ë¶€\":\n",
    "        print(f\"[ì˜ˆì™¸ì²˜ë¦¬] {meta.get('ë²•ë ¹ëª…', 'ì•Œ ìˆ˜ ì—†ìŒ')}ì€ ì „ë¶€ê°œì •ìœ¼ë¡œ ë¹„êµ ìƒëµ\")\n",
    "        return meta\n",
    "\n",
    "    table_section = extract_table_section(text)\n",
    "    old_text, new_text = split_left_right(table_section)\n",
    "    old_clauses = split_by_clause(old_text)\n",
    "    new_clauses = split_by_clause(new_text)\n",
    "    result = compare_clauses_v2(old_clauses, new_clauses)\n",
    "    save_to_csv(result, output_csv)\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48822858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ì˜ˆì‹œ ===\n",
    "meta_info = process_single_pdf(\"../data/no_upload/2210568_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\", \"../data/processed/ì¡°ë¬¸_ë¹„êµê²°ê³¼_v3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a355d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/processed/ì¡°ë¬¸_ë¹„êµê²°ê³¼_v3.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.to_excel(\"../data/processed/ì¡°ë¬¸_ë¹„êµê²°ê³¼_v3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decdcdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ì¡°ë¬¸ ID   3 non-null      object\n",
      " 1   êµ¬ì¡°ë¬¸     3 non-null      object\n",
      " 2   ì‹ ì¡°ë¬¸     1 non-null      object\n",
      " 3   ë³€ê²½ìœ í˜•    3 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 228.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.columns\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1121934",
   "metadata": {},
   "source": [
    "ì—‘ì…€ êµ¬ì„±ì— ë§ì¶° ì½”ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ âœ…\n",
    "\n",
    "ë³€ê²½ì‚¬í•­:\n",
    "\n",
    "ê° ì¡°ë¬¸ IDë¥¼ ì¡° / í•­ / í˜¸ / ëª©ìœ¼ë¡œ ë¶„ë¦¬\n",
    "\n",
    "CSV ì»¬ëŸ¼: ë²•ë ¹ëª…, ê°œì •ìœ í˜•, ì¡°ë¬¸ID, ì¡°, í•­, í˜¸, ëª©, êµ¬ì¡°ë¬¸, ì‹ ì¡°ë¬¸, ë³€ê²½ìœ í˜•\n",
    "\n",
    "compare_clauses_v3()ì™€ save_to_csv_v3() ë°˜ì˜\n",
    "\n",
    "ì „ë¶€ê°œì • ì˜ˆì™¸ì²˜ë¦¬ ìœ ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf89499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "import csv\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        text = \"\\n\".join(\n",
    "            page.extract_text() for page in pdf.pages if page.extract_text()\n",
    "        )\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_meta(text):\n",
    "    meta = {}\n",
    "    law_match = re.search(r\"([\\w\\dê°€-í£]+ë²•)\\s*(ì¼ë¶€|ì „ë¶€)?ê°œì •ë²•ë¥ ì•ˆ\", text)\n",
    "    if law_match:\n",
    "        meta[\"ë²•ë ¹ëª…\"] = law_match.group(1)\n",
    "        meta[\"ê°œì •ìœ í˜•\"] = law_match.group(2)\n",
    "    bill_match = re.search(r\"ì˜ì•ˆ[\\s:ï¼š]*ë²ˆí˜¸[\\s:ï¼š]*(ì œ?\\d+í˜¸)\", text)\n",
    "    if bill_match:\n",
    "        meta[\"ì˜ì•ˆë²ˆí˜¸\"] = bill_match.group(1)\n",
    "    date_match = re.search(r\"ë°œì˜[\\s:ï¼š]*ì—°ì›”ì¼[\\s:ï¼š]*([\\d\\.\\-]+)\", text)\n",
    "    if date_match:\n",
    "        meta[\"ë°œì˜ì—°ì›”ì¼\"] = date_match.group(1)\n",
    "    return meta\n",
    "\n",
    "\n",
    "def extract_table_section(text):\n",
    "    lines = text.splitlines()\n",
    "    start_idx = next((i for i, line in enumerate(lines) if \"ì‹ \" in line and \"êµ¬\" in line), 0)\n",
    "    return \"\\n\".join(lines[start_idx:])\n",
    "\n",
    "\n",
    "def split_left_right(text):\n",
    "    lines = text.splitlines()\n",
    "    left_lines, right_lines = [], []\n",
    "    midpoint = max(len(line) for line in lines) // 2\n",
    "    for line in lines:\n",
    "        left = line[:midpoint].strip()\n",
    "        right = line[midpoint:].strip()\n",
    "        left_lines.append(left)\n",
    "        right_lines.append(right)\n",
    "    return \"\\n\".join(left_lines), \"\\n\".join(right_lines)\n",
    "\n",
    "\n",
    "def split_by_clause(text):\n",
    "    pattern = r\"(ì œ\\d+ì¡°(?:\\s*ì œ\\d+í•­)?(?:\\s*ì œ\\d+í˜¸)?(?:\\s*ì œ\\d+ëª©)?)\"\n",
    "    parts = re.split(pattern, text)\n",
    "    clauses = []\n",
    "    for i in range(1, len(parts), 2):\n",
    "        law_id = parts[i].strip()\n",
    "        law_body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "        clauses.append((law_id, law_body))\n",
    "    return clauses\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    remove_keywords = [\"í˜„í–‰ê³¼ ê°™ìŒ\", \"------\", \"ìƒëµ\"]\n",
    "    lines = text.splitlines()\n",
    "    lines = [line.strip() for line in lines if line.strip() and not any(k in line for k in remove_keywords)]\n",
    "    return \" \".join(lines)\n",
    "\n",
    "\n",
    "def parse_clause_id(clause_id):\n",
    "    jo = hang = ho = mok = \"\"\n",
    "    m = re.match(r\"ì œ(\\d+)ì¡°(?:\\s*ì œ(\\d+)í•­)?(?:\\s*ì œ(\\d+)í˜¸)?(?:\\s*ì œ(\\d+)ëª©)?\", clause_id)\n",
    "    if m:\n",
    "        jo, hang, ho, mok = m.groups()\n",
    "    return jo or \"\", hang or \"\", ho or \"\", mok or \"\"\n",
    "\n",
    "\n",
    "def compare_clauses_v3(old_clauses, new_clauses, law_name, revision_type, threshold=0.85):\n",
    "    results = []\n",
    "    old_dict = {cid: clean_text(text) for cid, text in old_clauses}\n",
    "    new_ids = set(cid for cid, _ in new_clauses)\n",
    "\n",
    "    for cid, new_text_raw in new_clauses:\n",
    "        new_text = clean_text(new_text_raw)\n",
    "        old_text = old_dict.get(cid)\n",
    "        jo, hang, ho, mok = parse_clause_id(cid)\n",
    "        if old_text:\n",
    "            sim = SequenceMatcher(None, old_text, new_text).ratio()\n",
    "            if sim < threshold:\n",
    "                results.append([law_name, revision_type, cid, jo, hang, ho, mok, old_text, new_text, \"ìˆ˜ì •\"])\n",
    "        else:\n",
    "            results.append([law_name, revision_type, cid, jo, hang, ho, mok, \"\", new_text, \"ì‹ ì„¤\"])\n",
    "\n",
    "    for cid, old_text_raw in old_clauses:\n",
    "        if cid not in new_ids:\n",
    "            old_text = clean_text(old_text_raw)\n",
    "            jo, hang, ho, mok = parse_clause_id(cid)\n",
    "            results.append([law_name, revision_type, cid, jo, hang, ho, mok, old_text, \"\", \"ì‚­ì œ\"])\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_to_csv_v3(data, path):\n",
    "    with open(path, mode=\"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"ë²•ë ¹ëª…\", \"ê°œì •ìœ í˜•\", \"ì¡°ë¬¸ID\", \"ì¡°\", \"í•­\", \"í˜¸\", \"ëª©\", \"êµ¬ì¡°ë¬¸\", \"ì‹ ì¡°ë¬¸\", \"ë³€ê²½ìœ í˜•\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def process_single_pdf_v3(pdf_path, output_csv):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    meta = extract_meta(text)\n",
    "    if meta.get(\"ê°œì •ìœ í˜•\") == \"ì „ë¶€\":\n",
    "        print(f\"[ì˜ˆì™¸ì²˜ë¦¬] {meta.get('ë²•ë ¹ëª…', 'ì•Œ ìˆ˜ ì—†ìŒ')}ì€ ì „ë¶€ê°œì •ìœ¼ë¡œ ë¹„êµ ìƒëµ\")\n",
    "        return meta\n",
    "\n",
    "    law_name = meta.get(\"ë²•ë ¹ëª…\", \"\")\n",
    "    revision_type = meta.get(\"ê°œì •ìœ í˜•\", \"\")\n",
    "\n",
    "    table_section = extract_table_section(text)\n",
    "    old_text, new_text = split_left_right(table_section)\n",
    "    old_clauses = split_by_clause(old_text)\n",
    "    new_clauses = split_by_clause(new_text)\n",
    "    result = compare_clauses_v3(old_clauses, new_clauses, law_name, revision_type)\n",
    "    save_to_csv_v3(result, output_csv)\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdaf71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info = process_single_pdf_v3(\"../data/no_upload/2210568_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf\", \"../data/processed/ì¡°ë¬¸_ë¹„êµê²°ê³¼_v3_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc9ac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ì¡°ë¬¸ ID   3 non-null      object\n",
      " 1   êµ¬ì¡°ë¬¸     3 non-null      object\n",
      " 2   ì‹ ì¡°ë¬¸     1 non-null      object\n",
      " 3   ë³€ê²½ìœ í˜•    3 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 228.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.columns\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7abe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/ì¡°ë¬¸_ë¹„êµê²°ê³¼_v3_2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.to_excel(\"../data/processed/ì¡°ë¬¸_ë¹„êµê²°ê³¼_v3_2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23c8a0",
   "metadata": {},
   "source": [
    "# âŒ v3 ì‹¤íŒ¨ ì›ì¸ ë¶„ì„: \"ìƒê°€ê±´ë¬¼ ì„ëŒ€ì°¨ë³´í˜¸ë²•\" ì‚¬ë¡€\n",
    "\n",
    "## ğŸ“ ìš”ì•½\n",
    "- ë¬¸ì„œ: `2210568_ì˜ì‚¬êµ­ ì˜ì•ˆê³¼_ì˜ì•ˆì›ë¬¸.pdf`\n",
    "- ë¬¸ì œ: **ì‹¤ì œ ë³€ê²½ ì‚¬í•­ì´ ì¶”ì¶œë˜ì§€ ì•Šê±°ë‚˜, ë³€ê²½ ìœ í˜• ì˜¤ì¸**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‰ ì‹¤íŒ¨ ì›ì¸ ëª©ë¡\n",
    "\n",
    "### 1. **ì‹ Â·êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ êµ¬ê°„ ì¶”ì¶œ ë¯¸í¡**\n",
    "- ë¬¸ì œ: `extract_table_section()`ì´ `\"ì‹ \"`ê³¼ `\"êµ¬\"` í¬í•¨ ë¼ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ì„œ **ë¶€ì •í™•í•œ ì‹œì‘ì ì—ì„œ ì‹œì‘**\n",
    "- ê²°ê³¼: ì‹ Â·êµ¬ ì¡°ë¬¸ì´ ì•„ë‹Œ ë³¸ë¬¸ ì¼ë¶€ê°€ í¬í•¨ë˜ê±°ë‚˜ ì˜ë¦¼\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **ì¢Œ/ìš° ë¶„ë¦¬ ì‹¤íŒ¨**\n",
    "- ë¬¸ì œ: `split_left_right()`ê°€ **ê³ ì • `midpoint` ê¸°ì¤€ ìë¥´ê¸°**\n",
    "- ì‹¤ì œ PDFëŠ” ì¤„ë§ˆë‹¤ ì¢Œìš° í­ì´ ë‹¬ë¼, **êµ¬ì¡°ë¬¸/ì‹ ì¡°ë¬¸ì´ ì„ì„**\n",
    "- íŠ¹íˆ `ì œ19ì¡°ì˜2` ì‹ ì„¤ ì¡°ë¬¸ì€ ì˜¤ë¥¸ìª½ ì „ì²´ì—ë§Œ ìˆìŒ â†’ **ì¢Œì¸¡ì—ë„ ë‚¨ëŠ” í…ìŠ¤íŠ¸ ë°œìƒ**\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **ì¡°ë¬¸ êµ¬ë¶„ ì •í™•ë„ ì €í•˜**\n",
    "- ë¬¸ì œ: `split_by_clause()`ì˜ ì •ê·œì‹ì´ **\"ì œXì¡°\"ë§Œ ì¸ì‹**í•˜ê³  ì´í›„ í•­, í˜¸, ëª©ì€ ì œëŒ€ë¡œ ëŒ€ì‘ ì•ˆ ë¨\n",
    "- ì¡°ë¬¸ ì—†ì´ ì´ì–´ì§€ëŠ” ë¬¸ë‹¨ì€ **ë¬¶ì´ì§€ ì•Šê±°ë‚˜ ì˜ë¦¼**\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **ìœ ì‚¬ë„ ê¸°ë°˜ ë¹„êµì˜ í•œê³„**\n",
    "- ë¬¸ì œ: `SequenceMatcher`ëŠ” ê°„ë‹¨í•œ ë¬¸ì¥ ë¹„êµì— ì í•©í•˜ì§€ë§Œ,\n",
    "  - ì¡°ë¬¸ í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ ì§§ê³  í•µì‹¬ ë³€ê²½ë§Œ ìˆì–´ë„ **ìˆ˜ì •ì¸ì§€ ì‹ ì„¤ì¸ì§€ êµ¬ë¶„ ì‹¤íŒ¨**\n",
    "- ì˜ˆ: `ë¶„ë‹´` â†’ `ë¶„ë‹´, ê´€ë¦¬ë¹„ ë¶€ê³¼ í•­ëª©` â†’ `ìˆ˜ì •` ì¸ì‹ ëª» í•¨\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **ì‹ ì„¤ ì¡°ë¬¸ ëˆ„ë½**\n",
    "- ë¬¸ì œ: ì‹ ì„¤ëœ `ì œ19ì¡°ì˜2`ëŠ” **ì¢Œì¸¡ì— ì¡°ë¬¸ IDê°€ ì—†ìŒ**\n",
    "- `split_by_clause()`ê°€ ì´ë¥¼ ì¸ì‹ ëª»í•´ **ì¡°ë¬¸ ID ì—†ì´ ëˆ„ë½ë˜ê±°ë‚˜ ì“°ë ˆê¸°ê°’ìœ¼ë¡œ ì²˜ë¦¬**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ ê°œì„  í¬ì¸íŠ¸ (v4 ê³„íš ìš”ì†Œ)\n",
    "\n",
    "| ì‹¤íŒ¨ ì›ì¸ | ê°œì„  ë°©ì•ˆ |\n",
    "|-----------|-----------|\n",
    "| ì‹ Â·êµ¬ êµ¬ì¡°ë¬¸ êµ¬ê°„ íƒìƒ‰ | \"ì‹ Â·êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ\" í‚¤ì›Œë“œì™€ ìœ„ì¹˜ ê¸°ë°˜ íƒì§€ |\n",
    "| ì¢Œìš° ë¶„ë¦¬ | `pdfplumber`ì˜ `char.bbox` ë˜ëŠ” `layout` ì •ë³´ í™œìš© |\n",
    "| ì¡°ë¬¸ ì¶”ì¶œ | \"ì œXì¡° ì œXí•­â€¦\" íŒ¨í„´ ê°•í™” + ì¡°ë¬¸ ì—†ìŒ ê°ì§€ ë¡œì§ ì¶”ê°€ |\n",
    "| ë¹„êµ ë¡œì§ | `SequenceMatcher` â†’ `BLEU` or `Jaccard`, ë˜ëŠ” LLM ìš”ì•½ ê¸°ë°˜ ë¹„êµ |\n",
    "| ì‹ ì„¤ ëˆ„ë½ ë°©ì§€ | ì¡°ë¬¸ ID ì—†ìŒ â†’ 'ì‹ ì„¤ í›„ë³´'ë¡œ íƒœê¹…í•˜ì—¬ ìˆ˜ë™ê²€í†  ëª©ë¡ í¬í•¨ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‚ ê²°ë¡ \n",
    "- í˜„ì¬ íŒŒì´í”„ë¼ì¸ì€ \"í•œìª½ì´ ì™„ì „íˆ ë¹„ì–´ìˆê±°ë‚˜ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ê²½ìš°\" ì™„ì „ ì‹¤íŒ¨\n",
    "- `ì¢Œìš° ë¶„ë¦¬ ë°©ì‹`, `ì •ê·œì‹ ê¸°ë°˜ ì¡°ë¬¸ ì¶”ì¶œ`, `ê°„ë‹¨í•œ ìœ ì‚¬ë„ ë¹„êµ` â†’ **ë‹¤ìŒ ë²„ì „ì—ì„œ ë°˜ë“œì‹œ ë³´ì™„ í•„ìš”**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
