{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0fcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "import csv\n",
    "from difflib import SequenceMatcher\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c50491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_left_right_columns(pdf_path):\n",
    "    \"\"\"\n",
    "    PDFì—ì„œ ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ ì˜ì—­ì˜ ì¢Œì¸¡(í˜„í–‰) / ìš°ì¸¡(ê°œì •) ì—´ì„ ë‚˜ëˆ„ì–´ ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    left_clauses, right_clauses = [], []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            words = page.extract_words()\n",
    "            if not words:\n",
    "                continue\n",
    "            midpoint = (page.bbox[2] - page.bbox[0]) / 2\n",
    "            left_lines = {}\n",
    "            right_lines = {}\n",
    "            for w in words:\n",
    "                y0 = round(w[\"top\"])\n",
    "                text = w[\"text\"].strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                target = left_lines if w[\"x0\"] < midpoint else right_lines\n",
    "                if y0 not in target:\n",
    "                    target[y0] = []\n",
    "                target[y0].append(text)\n",
    "            for y in sorted(left_lines):\n",
    "                left_clauses.append(\" \".join(left_lines[y]))\n",
    "            for y in sorted(right_lines):\n",
    "                right_clauses.append(\" \".join(right_lines[y]))\n",
    "    return left_clauses, right_clauses\n",
    "\n",
    "\n",
    "def merge_by_clause(lines):\n",
    "    \"\"\"ì œXXì¡°, â‘ , 1. ê¸°ì¤€ìœ¼ë¡œ ì¡°ë¬¸ ë¬¶ê¸°\"\"\"\n",
    "    clause_blocks = []\n",
    "    current_clause = \"\"\n",
    "    clause_id = \"\"\n",
    "    for line in lines:\n",
    "        if re.match(r\"ì œ\\d+ì¡°\", line):\n",
    "            if current_clause:\n",
    "                clause_blocks.append((clause_id, current_clause.strip()))\n",
    "            clause_id = re.findall(r\"ì œ\\d+ì¡°(?:\\s*ì œ\\d+í•­)?\", line)[0]\n",
    "            current_clause = line\n",
    "        elif re.match(r\"[\\(\\[]?\\d+[\\)\\.]\", line) or re.match(r\"[\\u2460-\\u2473]\", line):\n",
    "            current_clause += \"\\n\" + line\n",
    "        else:\n",
    "            current_clause += \" \" + line\n",
    "    if current_clause:\n",
    "        clause_blocks.append((clause_id, current_clause.strip()))\n",
    "    return clause_blocks\n",
    "\n",
    "\n",
    "def compare_clauses(old_clauses, new_clauses, threshold=0.85):\n",
    "    \"\"\"\n",
    "    ì¡°ë¬¸ ID ê¸°ì¤€ìœ¼ë¡œ ë¹„êµ í›„ ë³€ê²½ ìœ í˜• ë¶„ë¥˜\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    old_dict = {cid: text for cid, text in old_clauses}\n",
    "    new_ids = set(cid for cid, _ in new_clauses)\n",
    "\n",
    "    for cid, new_text in new_clauses:\n",
    "        old_text = old_dict.get(cid)\n",
    "        if old_text:\n",
    "            sim = SequenceMatcher(None, old_text, new_text).ratio()\n",
    "            if sim < threshold:\n",
    "                results.append((cid, old_text, new_text, \"ë³€ê²½\"))\n",
    "        else:\n",
    "            results.append((cid, \"\", new_text, \"ì‹ ì„¤\"))\n",
    "\n",
    "    for cid, old_text in old_clauses:\n",
    "        if cid not in new_ids:\n",
    "            results.append((cid, old_text, \"\", \"ì‚­ì œ\"))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_to_csv(data, path, law_name=\"\"):\n",
    "    with open(path, mode=\"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"ë²•ë¥ ëª…\", \"ì¡°ë¬¸ID\", \"í˜„í–‰\", \"ê°œì •\", \"ë³€ê²½ìœ í˜•\"])\n",
    "        for cid, old, new, chg in data:\n",
    "            writer.writerow([law_name, cid, old, new, chg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83540c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ì‹¤í–‰ ===\n",
    "\n",
    "folder_path = r\"C:\\Jimin\\cg_DeltaLaw\\data\\no_upload\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for file in file_list:\n",
    "    path = os.path.join(folder_path, file)\n",
    "    left, right = extract_left_right_columns(path)\n",
    "    old_clauses = merge_by_clause(left)\n",
    "    new_clauses = merge_by_clause(right)\n",
    "    results = compare_clauses(old_clauses, new_clauses)\n",
    "    save_to_csv(results, \"ì¡°ë¬¸_ë¹„êµê²°ê³¼.csv\", law_name=file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb118228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "base_path = r\"C:\\Jimin\\cg_DeltaLaw\\data\"\n",
    "folder_path = os.path.join(base_path, \"no_upload\")\n",
    "output_path = os.path.join(base_path, \"processed\", \"ì¡°ë¬¸_ì „ì²´ë¹„êµê²°ê³¼.csv\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if not file.endswith(\".pdf\"):\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    # ë²•ë¥ ëª… ì¶”ì¶œ ì˜ˆì‹œ: íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ PDF ì²« í˜ì´ì§€ì—ì„œ íŒŒì‹±\n",
    "    law_name = os.path.splitext(file)[0]  # ë‹¨ìˆœíˆ íŒŒì¼ëª… ê¸°ë°˜\n",
    "    try:\n",
    "        left, right = extract_left_right_columns(file_path)\n",
    "        old_clauses = merge_by_clause(left)\n",
    "        new_clauses = merge_by_clause(right)\n",
    "        results = compare_clauses(old_clauses, new_clauses)\n",
    "\n",
    "        # ê° ê²°ê³¼ì— ë²•ë¥ ëª… ì¶”ê°€\n",
    "        for cid, old, new, chg in results:\n",
    "            all_results.append([law_name, cid, old, new, chg])\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {file} â†’ {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed59ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§ˆì§€ë§‰ì— CSVë¡œ ì €ì¥\n",
    "with open(output_path, mode=\"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"ë²•ë¥ ëª…\", \"ì¡°ë¬¸ID\", \"í˜„í–‰\", \"ê°œì •\", \"ë³€ê²½ìœ í˜•\"])\n",
    "    writer.writerows(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e1ee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284 entries, 0 to 283\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ë²•ë¥ ëª…     284 non-null    object\n",
      " 1   ì¡°ë¬¸ID    266 non-null    object\n",
      " 2   í˜„í–‰      268 non-null    object\n",
      " 3   ê°œì •      74 non-null     object\n",
      " 4   ë³€ê²½ìœ í˜•    284 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 11.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Jimin\\cg_DeltaLaw\\data\\processed\\ì¡°ë¬¸_ì „ì²´ë¹„êµê²°ê³¼.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.columns\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffdcbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Jimin\\cg_DeltaLaw\\data\\processed\\ì¡°ë¬¸_ì „ì²´ë¹„êµê²°ê³¼.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.to_excel(r\"C:\\Jimin\\cg_DeltaLaw\\data\\processed\\ì¡°ë¬¸_ì „ì²´ë¹„êµê²°ê³¼.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3367def",
   "metadata": {},
   "source": [
    "## âŒ 1ì°¨ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ì›ì¸ ì •ë¦¬\n",
    "\n",
    "### 1. ì¡°ë¬¸ ID ë§¤ì¹­ ì‹¤íŒ¨\n",
    "- `\"ì œXì¡°\"` í˜•íƒœ ì¶”ì¶œì´ ë¶ˆì•ˆì •í•˜ê±°ë‚˜ ì¼ë¶€ ëˆ„ë½ë¨\n",
    "- í˜„í–‰ â†” ê°œì • ì¡°ë¬¸ ê°„ 1:1 ë§¤ì¹­ ì‹¤íŒ¨\n",
    "\n",
    "### 2. ì¢Œ/ìš° ì—´ ì¶”ì¶œ ì‹¤íŒ¨\n",
    "- ì¼ë¶€ PDFì—ì„œ ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œì˜ **ì¢Œìš° ì—´ ì¸ì‹ì´ ì–´ê¸‹ë‚¨**\n",
    "- `midpoint` ê¸°ì¤€ ë‹¨ìˆœ ë¶„í• ë¡œëŠ” **ëª¨ë“  í¬ë§· ì»¤ë²„ ë¶ˆê°€**\n",
    "\n",
    "### 3. ë¶ˆí•„ìš”í•œ ì¤„ í¬í•¨\n",
    "- `\"í˜„í–‰ê³¼ ê°™ìŒ\"`, `\"ìƒëµ\"`, `\"------\"` ë“± **ì˜ë¯¸ ì—†ëŠ” í…ìŠ¤íŠ¸ í¬í•¨**\n",
    "- ì „ì²˜ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ê²°ê³¼ ì •í•©ì„± ì €í•˜\n",
    "\n",
    "### 4. ë³€ê²½ìœ í˜• ë¶„ë¥˜ ì •í™•ë„ ë‚®ìŒ\n",
    "- `SequenceMatcher` ê¸°ë°˜ ìœ ì‚¬ë„ íŒì •ì´ **ë„ˆë¬´ ë‹¨ìˆœ**\n",
    "- ì‹¤ì œ ë³€ê²½ ì•„ë‹˜ì—ë„ `\"ë³€ê²½\"`ìœ¼ë¡œ ì˜¤ë¶„ë¥˜í•˜ê±°ë‚˜ ë°˜ëŒ€ ìƒí™© ë°œìƒ\n",
    "\n",
    "### 5. ë²•ë¥ ëª… ì‹ë³„ ë¯¸í¡\n",
    "- ë‹¨ìˆœíˆ íŒŒì¼ëª…ìœ¼ë¡œë§Œ ë²•ë¥ ëª…ì„ ì¶”ì •\n",
    "- **ì •í™•í•œ ë²•ë¥ ëª… ì¶”ì¶œ ë¡œì§ ë¶€ì¬**\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“Œ ìœ„ ë¬¸ì œì ì„ ê¸°ì¤€ìœ¼ë¡œ **v2 íŒŒì´í”„ë¼ì¸ ì„¤ê³„ì— ë°˜ì˜ ì˜ˆì •**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
